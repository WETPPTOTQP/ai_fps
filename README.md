# 本项目基于好想摸鱼（https://wsblog.netlify.app/2023/01/30/2.aimyolo/）的项目修改

基于 YOLOv5 的射击类游戏瞄准辅助工具。支持屏幕实时检测、人头/身体目标识别、单次锁定与自动鼠标跟随。该版本适用于 Windows。因为样本原因，并没有相当数量的训练数据，本项目仅用于试验视觉处理的fps辅助工具，该版本屏幕检测速率较低，鼠标锁定跟随速度较低。严禁任何破坏游戏平衡做法。

---

## 主要特性

- 实时屏幕检测与弹窗显示（OpenCV）。
- 两类目标：`head`（类别0）与 `body`（类别1）。
- 中键单次识别并锁定，F1/F2 快速切换锁定目标类型（头/身体）。
- 自动鼠标跟随移动，可调速度与跟随半径（在crow_changed\z_detect5.py中190、191行修改鼠标移动速度；在200行中修改跟随半径；在489行中修改锁定中心半径；在479行中修改置信度阈值；在480行中修改NMS IOU 阈值；在488行中修改锁定最低置信度）。
- 离线图片检测模式（一次检测后退出，试验模型是否能识别）。
- 权重自动解析：优先你的训练输出（可在z_detect5.py中第45、46行修改），再回退至项目默认权重。

---


## 依赖安装

请先运行 `requirements.txt`，安装核心依赖：

---


## 快速开始

- 观测模式（不移动鼠标，推荐先验证）：

```bash
python z_detect5.py --view-img --no-move
```

- 正常模式（弹窗与鼠标移动）：

```bash
python z_detect5.py --view-img
```

- 离线图片检测（一次检测后退出）：

```bash
python z_detect5.py --image-path <你的图片路径> --view-img
```

---

## 交互与控制

- 中键点击：发起一次识别并锁定（再次点击取消锁定）
- F1：切换锁定目标为“头部”
- F2：切换锁定目标为“身体”
- P：退出程序

---

## 自己训练

- 训练：运行`train.py`（按你的数据与标签进行训练后，权重会输出到 `runs/<exp>/weights/`）

---

## 合规与免责声明

- 请遵守游戏及平台的使用条款与法律法规，仅用于学习研究。
- 在公共或竞争环境中使用可能导致账号风险，请谨慎评估。

---

## 致谢

- 本项目参考并基于 YOLOv5 相关实现，感谢社区的开源贡献，感谢博主好想摸鱼（https://wsblog.netlify.app/2023/01/30/2.aimyolo/）


